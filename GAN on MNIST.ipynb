{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e3eda86d4ce3d1d5b2b206a1d01c70f9ee8d0d3"
   },
   "source": [
    "This kernel use DCGAN(Deep Convolutional Generative Adversarial Network) to generate different MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04304e5c4555849eade69a1a1b5b1fb7cc2feb13"
   },
   "source": [
    "## Set up network parameters\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38443112fd55bef54d7807495b69d66353bfccae"
   },
   "outputs": [],
   "source": [
    "img_rows = 28\n",
    "img_cols = 28\n",
    "channels = 1\n",
    "img_shape = (img_rows, img_cols, channels)\n",
    "latent_dim = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c5ad4f2b1b3b4ae3dd6caf7ba96ef1e273eb900"
   },
   "source": [
    "## Define a function to build a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "804d0ab8433b786150c48cd6bd990d74705cb2a8"
   },
   "outputs": [],
   "source": [
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.summary()\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    img = model(noise)\n",
    "    return Model(noise, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a9ea4efecf7d4faeb0a37a649c079ebe88396908"
   },
   "source": [
    "## Define a function to build a discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9aa34a385dac406b50e7e122b45483c98c0cffa"
   },
   "outputs": [],
   "source": [
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.summary()\n",
    "    img = Input(shape=img_shape)\n",
    "    validity = model(img)\n",
    "    return Model(img, validity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "306fda1d4980efc3c64db997111ab7e615cfdbac"
   },
   "source": [
    "## Build GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f7202cc45aae945674176146922493812e520030"
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# build discriminator\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy',\n",
    "                      optimizer=optimizer,\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "# build generator\n",
    "generator = build_generator()\n",
    "z = Input(shape=(100,))\n",
    "img = generator(z)\n",
    "\n",
    "# For the combined model we will only train the generator\n",
    "discriminator.trainable = False\n",
    "\n",
    "# The discriminator takes generated images as input and determines validity\n",
    "valid = discriminator(img)\n",
    "\n",
    "# The combined model  (stacked generator and discriminator)\n",
    "# Trains the generator to fool the discriminator\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e1d9927bd8601eedf144b6f46f12cc4da0d045b5"
   },
   "source": [
    "## Define a function to train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6592840f1e019f1d6fd3e709a0885389d252164f"
   },
   "outputs": [],
   "source": [
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "    os.makedirs('images', exist_ok=True)\n",
    "    \n",
    "    # Load the dataset\n",
    "    (X_train, _), (_, _) = mnist.load_data()\n",
    "\n",
    "    # Rescale -1 to 1\n",
    "    X_train = X_train / 127.5 - 1.\n",
    "    X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "    # Adversarial ground truths\n",
    "    valid = np.ones((batch_size, 1))\n",
    "    fake = np.zeros((batch_size, 1))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Select a random real images\n",
    "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "        real_imgs = X_train[idx]\n",
    "\n",
    "        # Sample noise and generate a batch of fake images\n",
    "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
    "        fake_imgs = generator.predict(noise)\n",
    "\n",
    "        # Train the discriminator\n",
    "        D_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
    "        D_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
    "        D_loss = 0.5 * np.add(D_loss_real, D_loss_fake)\n",
    "\n",
    "        # Train the generator\n",
    "        g_loss = combined.train_on_batch(noise, valid)\n",
    "\n",
    "        # If at save interval\n",
    "        if epoch % save_interval == 0:\n",
    "            # Print the progress\n",
    "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, D_loss[0], 100 * D_loss[1], g_loss))\n",
    "            # Save generated image samples\n",
    "            save_imgs(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b03c0413ddcde5125fa8fdb22bfe47e1bd668606"
   },
   "outputs": [],
   "source": [
    "def save_imgs(epoch):\n",
    "    r, c = 5, 5\n",
    "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
    "    gen_imgs = generator.predict(noise)\n",
    "\n",
    "    # Rescale images 0 - 1\n",
    "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "    fig, axs = plt.subplots(r, c)\n",
    "    cnt = 0\n",
    "    for i in range(r):\n",
    "        for j in range(c):\n",
    "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "            axs[i, j].axis('off')\n",
    "            cnt += 1\n",
    "    fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ccbe0a280b9fc16e47a63dc5e5edae8909f7569c"
   },
   "source": [
    "## Train GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8a52d992f11a034e0cc0cabaddeb2ae93f160dc6"
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "train(epochs=10000, batch_size=32, save_interval=1000)\n",
    "\n",
    "end = time.time()\n",
    "elapsed_train_time = 'elapsed training time: {} min, {} sec '.format(int((end - start) / 60),\n",
    "                                                                     int((end - start) % 60))\n",
    "print(elapsed_train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "cb7c9e65347eb077e1dabd74445713ddef12ba34"
   },
   "outputs": [],
   "source": [
    "os.makedirs('saved_model_weights', exist_ok=True)\n",
    "generator.save_weights('saved_model_weights/generator_weights.h5')\n",
    "discriminator.save_weights('saved_model_weights/discriminator_weights.h5')\n",
    "combined.save_weights('saved_model_weights/combined_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "526455382f869ceadc4206cb703e676a4037b213",
    "collapsed": true
   },
   "source": [
    "## Show generated MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b9cd883f622680511e19cfa30717a3a8d93c4a48"
   },
   "outputs": [],
   "source": [
    "Image.open('images/mnist_1000.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4c487c7fede8db3baa681554c9cf677464af791c"
   },
   "outputs": [],
   "source": [
    "Image.open('images/mnist_9000.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
